% Chapter 3

\chapter{Related Work} % Main chapter title

\label{Chapter3} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 3. \emph{Related Work}} % This is for the header on each page - perhaps a shortened title

%------------------------

---------------------------------------------------------------

This section describes the most current deep-learning-based lane detecting systems. Current approaches may be grouped into three groups depending on the strategy of line form description: traditional methods, Convolutional Neural Network (CNN) models, Deep Learning (DL) methods.


\section{Traditional Methods}

Traditional Methods in car lane detection rely on a combination of highly specialized, refined features and heuristics to along with the region of interest concepts to enable detection.\cite{neven_towards_2018} Mathematical implementations such as Canny edge Detection, Hough Transformations as well as Sobel filter methods are used to detect the lane lines. The Canny edge detector technique is utilized to identify road edges, while the Hough transformation method can be defined as a process which finds and shows shapes in the particular image input.\cite{wang_lanenet_2018} To decrease noise and improve accuracy, the region of interest (ROI) is computed in real time. It is also effective for shortening the execution time.  Sobel filter method is usually used as a edge detection algorithm in image processing where the gray scale colour space is closer to the edge information in the actual image.\cite{fong_real-time_2020}\cite{kamci_lane_2019} Recent research has been done in refined methods such as colour based methodologies\cite{1505186}, structural features\cite{neven2017fast}, the bar filter\cite{teng2010}, ridge features\cite{lopez2010} along with a Hough Transform\cite{liu2010}\cite{5548087}\cite{assidiq_real_2008} or particle or Kalman filters\cite{4459093}\cite{danescu2009}\cite{teng2010}. 
Hur et al.,(2013)\cite{hur_multi-lane_2013} proposed a new multi-lane detection algorithm which detects four lane marks, including driving lane marks and adjacent lane marks. In the study, they have included support for cross-sections as well as non-parallel lanes by implementing Conditional Random Fields (CRFs), which are strong models for solving multiple association tasks. 

\section{Convolutional Neural Network Models}
Convolutional neural networks (CNNs) are used in recent state-of-the-art lane identification techniques to train deep learning models using popular benchmarks such as TuSimple\cite{noauthor_tusimple_2021} and CULane\cite{CULane_Dataset}. While each of the following discussed models performs exceptionally well on train and test inputs from the same dataset, its performance suffers dramatically when tested on unknown datasets from various contexts.
Hang et al.,(2019)\cite{lo_multi-class_2019} proposes two CNN techniques which are Feature Size
Selection (FSS) and Degressive Dilation Block (DD Block). They introduced these methodologies to modify the existing semantic segmentation networks. EDANet\cite{lo2019efficient} was chosen as their baseline architecture due to it having a good balance between the efficiency and performance speed for a well defined autonomous driving model. For proper lane localisation, precise geographical information is required and so EDANet features three downsampling processes, whereas most CNNs contain multiple downsampling layers. The modified network achieved an Mean Intersection over Union (MIoU) score of 75.0 on the ITRI dataset.\cite{lo_multi-class_2019} 

Liu et al.,(2020)\cite{liu_lane_2020} present a method for increasing the environmental flexibility of the lane detector using Generative Adversarial Networks (GANs) to produce pictures in low-light circumstances. Their suggested approach is divided into three parts: the SIM-CycleGAN, the light conditions style transfer, and the lane identification network. They used ERFNet to evaluate their approaches on the lane detection benchmark CULane and received a 73.9 F-1 score.
Researchers have also worked on formulating feed-forward networks (FFNs) for parameter predictions which are then passed on and trained with a Hungarian fitting loss.\cite{liu_end--end_2020} This end-to-end model outputs parameters of a lane shape model based on a network which is built with a transformer encoder to capture and learn richer features from the images.  
Spatial CNN (SCNN) is a modified convolutional network proposed by Pan et al., (2018)\cite{pan_spatial_2017} that generalizes typical deep layer-by-layer convolutions to slice-by-slice convolutions inside feature maps, allowing message passings across pixels across rows and columns in a layer. They apply SCNN on Cityscapes dataset with an Intersection over Union (IoU) of 71.6 outperforming Recurrent Neural Network (RNN) based ReNet by 8.7\%. 

Chng et al.,(2020)\cite{chng_roneld_2020}, introduces a technique for identifying, tracking, and optimizing active lanes using deep learning probability map outputs using real-time robust neural network output enhancement for active lane identification (RONELD). The network adaptively extracts lane points from probability map outputs, then detects curved and straight lanes before applying weighted least squares linear regression on straight lanes to correct damaged lane edges caused by edge map fragmentation in actual pictures. Finally, they postulate genuine active lanes by tracking previous frames. On cross-dataset validation tests, experimental results show an up to two-fold boost in accuracy when using RONELD.  
According to Wang et al.(2021)\cite{wang_multitask_2021}, even if the accuracy of lane line prediction is improving, the capacity of lane markings to localize is rather limited, especially when the lane marking location is remote in nature. They offer a multi-task strategy that combines CNN's network to model semantic information with the high localization ability supplied by handmade features and forecasts the position of the vanishing line. The accuracy of location and network convergence speed are increased by incorporating segmentation, unique handcrafted characteristics, and fitting. Their network outperforms SCNN, ReNet by a huge margin on the benchmark dataset CuLane with a F-1 score of 69.6 for Curved Lanes. 

\section{Deep Learning Methods}

Xu et al.,(2020)\cite{xu_curvelane-nas_2020} provide CurveLane-NAS, a novel lane-sensitive architecture search framework for autonomously collecting both long-ranged coherent and accurate short-range curve information. It has three search modules: a feature fusion search module to investigate a better fusion of the local and global context for multi-level hierarchy features; an elastic backbone search module to investigate an efficient feature extractor with good semantics and latency; and an adaptive point blending module to investigate a multi-level post-processing refinement strategy to combine multi-scale head prediction. They also introduce the benchmark called CurveLanes\cite{soulmateb_soulmatebcurvelanes_2021} to include the most problematic curve lanes. It has 150K photos and 680K labels and their procedure model achieves an F1-score of 80.0. 
Zhang et al.,(2018)\cite{zhang_end_2018} present a deep learning model, Global Convolution Networks (GCN), that handles both classification and localization challenges in semantic lane segmentation. To attain cutting-edge performance, they employ color-based segmentation, a residual-based boundary refinement, and Adam optimization. 

Researchers\cite{liu_condlanenet_2021} introduce CondLaneNet which is a unique top-to-down lane identification framework that identifies lane instances first and then predicts the line shape for each instance dynamically. The research provides a conditional lane detection technique based on conditional convolution and row-wise formulation to re-solve the lane instance-level discriminating problem. Furthermore, they also introduce the Recurrent Instance Module (RIM) to address the issue of recognizing lane lines with complicated topologies, such as dense lines and fork lines. The advantage from their method is the real-time efficiency and end-to-end pipeline, which requires minimum post-processing. Furthermore, this approach combines accuracy and efficiency, as seen by a 78.14 F1 score and 220 FPS on CULane\cite{CULane_Dataset}. LaneNet is a deep learning module which has been presented by Neven et al.,(2018)\cite{neven_towards_2018} which performs end-to-end lane detection by combining binary lane segmentation with a clustering loss function designed for one-shot instance segmentation. the network generates parameters of a perspective transformation where lane fitting is optimal. LaneNet achieves an accuracy of 96.4\% on the TuSimple dataset.      

Yoo et al.,(2020)\cite{yoo_end--end_2020} view the problem not belonging to the instance segmentation field but as finding the set of horizontal locations of each lane marker in the input image. They propose a deep learning model which has been combined with lane marker-wise horizontal reduction modules (HRMs) on top of a end-to-end lane marker detection architecture (E2E-LMD). They achieve an F-1 socre of 74.0 against the benchmark CuLane and 96.06\% accuracy for TuSimple. Zou et al.,(2020)\cite{zou_robust_2020} examine lane detection utilizing numerous frames from a continuous driving scenario and propose a hybrid deep architecture that combines the convolutional neural network (CNN) and the recurrent neural network (RNN) (RNN). A CNN block extracts information from each frame, and the CNN features of numerous continuous frames with the property of time-series are then sent into the RNN block for feature learning and lane prediction.

Wang et al.,(2018)\cite{wang_lanenet_2018} devised a lane detecting approach that is comprised of two deep neural networks. The lane edge proposal network uses the initial input image of a vehicle's front view to generate a lane edge proposal map. The lane line localization network is then in charge of determining the position of each lane given by the lane edge map. The use of a deep neural network endows the method with great robustness, and the two-stage detection pipeline reduces computational cost and allows the lane line localization network to be trained in a manner that combines supervised and weekly supervised learning, resulting in a significant reduction in the cost of labeling training data.